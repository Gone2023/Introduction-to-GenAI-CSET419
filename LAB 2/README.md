# CSET419 – Introduction to Generative AI  
## Lab 2: Training a Generative Adversarial Network (GAN)

---

## Overview

This repository contains the implementation of **Lab–2** for the course **CSET419 – Introduction to Generative AI**.  
The objective of this lab is to design, train, and evaluate a **basic Generative Adversarial Network (GAN)** capable of generating realistic synthetic images using:

- **MNIST** (Handwritten Digits)
- **Fashion-MNIST** (Clothing Items)

Both experiments are implemented separately and fully documented.

---

## Aim

To implement and train a basic Generative Adversarial Network (GAN) to generate synthetic images similar to a given dataset and evaluate the quality of generated images using visual inspection and a classifier model.

---

## Key Concepts Used

- Generative Adversarial Networks (GANs)
- Generator and Discriminator Networks
- Adversarial Training
- Binary Cross-Entropy Loss
- Image Normalization
- Transfer Learning for Evaluation
- TensorFlow / Keras

---


## Dataset Details

| Dataset | Description | Image Size |
|-------|------------|------------|
| MNIST | Handwritten digits (0–9) | 28×28 grayscale |
| Fashion-MNIST | Clothing items (10 classes) | 28×28 grayscale |

Datasets are loaded using TensorFlow/Keras utilities and normalized to the range **[-1, 1]**.


dataset link : https://drive.google.com/drive/folders/1nrE2SgEg6PG2dW3NJIZ0p_heECpLOEMV?usp=drive_link

---

## User-Configurable Parameters

- `dataset_choice`: mnist or fashion  
- `epochs`: Number of training epochs  
- `batch_size`: Training batch size  
- `noise_dim`: Dimension of noise vector  
- `learning_rate`: Learning rate for optimizer  
- `save_interval`: Interval for saving generated images  

---

## Model Architecture

### Generator
- Input: Random noise vector  
- Dense layers with LeakyReLU activation  
- Output layer with `tanh` activation  
- Reshaped to 28×28×1 image  

### Discriminator
- Input: Image  
- Dense layers with LeakyReLU activation  
- Output: Probability (Real / Fake)  

---

## Training Process

1. Discriminator is trained on real images (label = 1).
2. Discriminator is trained on fake images generated by the Generator (label = 0).
3. Generator is trained to fool the Discriminator.
4. Training is performed in an alternating manner for multiple epochs.
5. Epoch-wise training logs are printed.

---

## Generated Outputs

### Training Logs

Epoch 10/50 | D_loss: 0.53 | D_acc: 78.12% | G_loss: 1.24


---

### Generated Samples During Training

- Images are saved at fixed intervals (e.g., every 5 epochs).
- Each image contains a 5×5 grid (25 samples).
- Stored in the `generated_samples` directory.

---

### Final Generated Images

- 100 synthetic images generated after training.
- Stored in the `final_generated_images` directory.

---

## Evaluation Using Classifier

A pre-trained CNN classifier is used to predict labels for the generated images.

Example output:

Label Distribution of Generated Images:
{0: 12, 1: 9, 2: 11, 3: 8, 4: 10, 5: 14, 6: 13, 7: 9, 8: 7, 9: 7}


---

## Saved Models

- `generator_model.h5`
- `discriminator_model.h5`
- `gan_model.h5`

These models can be reused for inference or further training.

---

## Results

- GAN successfully learned to generate dataset-like images.
- Image quality improved over training epochs.
- Classifier predictions confirmed meaningful class generation.
- Both MNIST and Fashion-MNIST experiments were completed successfully.

---

## Conclusion

This experiment demonstrates the practical implementation of Generative Adversarial Networks for image generation. GANs are effective for generating realistic synthetic data and are useful in data augmentation, digital archive restoration, and AI pipeline testing.

---

## Tools and Libraries Used

- Python
- TensorFlow / Keras
- NumPy
- Matplotlib
- Google Colab
- GitHub

---

## Course Information

- Course: CSET419 – Introduction to Generative AI  
- Lab: 2  
- Experiment: Train a Basic GAN Model for Image Generation  

---

## Notes

- Separate implementations are provided for MNIST and Fashion-MNIST.
- All outputs, trained models, and reports are included.
- Repository is structured for academic submission and evaluation.
